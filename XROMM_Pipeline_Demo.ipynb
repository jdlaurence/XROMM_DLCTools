{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RK255E7YoEIt"
   },
   "source": [
    "# DeepLabCut Toolbox\n",
    "https://github.com/AlexEMG/DeepLabCut\n",
    "\n",
    "Nath\\*, Mathis\\* et al. Using DeepLabCut for 3D markerless pose estimation during behavior across species.\n",
    "\n",
    "pre-print: https://www.biorxiv.org/content/10.1101/476531v1\n",
    "\n",
    "XROMMTools for DeepLabCut written by J.D. Laurence-Chasen\n",
    "\n",
    "This notebook walks you through the XMALab/DeepLabCut workflow, from project creation to analysis.\n",
    "\n",
    "\n",
    "At this stage, you should have tracked data in XMALab and exported the 2D points for trials you wish to be included in the initial training dataset. Each trial should have its own subfolder, containing only the images (image stack or video files) and the 2D points CSV. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages. Run this every time!\n",
    "import deeplabcut\n",
    "from deeplabcut.utils import xrommtools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Create a new project\n",
    "\n",
    "The first step is to create a DeepLabCut project (network) for each camera plane. Whether or not you create new projects for each day of data collection depends in large part on the variation in the dataset and number of markers. You should always create new projects for different individuals.\n",
    "\n",
    "N.B. If you are creating a new project for a different day of data collection on the same animal (or an animal with a similar marker scheme), it may be easier to manually copy an existing project and delete the folder contents to minimize config file editing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this section only once\n",
    "\n",
    "task='PigFeeding' # Enter the name of your experiment Task\n",
    "experimenter='JD' # Enter the name of the experimenter\n",
    "video=['C:/Users/jdlc7/PigDLC/pig20190227_cam1.avi'] # IMPORTANT: This video is a 'dummy' video. Just point the function to something. A future version will eliminate this step.\n",
    "working_directory = 'C:/Users/jdlc7/PigDLC_cam1' # where the project will be created; use forward slashes on Windows\n",
    "\n",
    "path_config_file_cam1=deeplabcut.create_new_project(task,experimenter,video,working_directory,copy_videos=False)\n",
    "\n",
    "# repeat for second camera\n",
    "video=['C:/Users/jdlc7/PigDLC/pig20190227_cam2.avi'] \n",
    "working_directory = 'C:/Users/jdlc7/PigDLC_cam2'\n",
    "path_config_file_cam2=deeplabcut.create_new_project(task,experimenter,video,working_directory,copy_videos=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "Now edit the newly created configuration file to match your project. See DLC methods paper for the significance of the different terms.\n",
    "\n",
    "ESSENTIAL: Make sure that video_sets: contains the dummy video (path doesn't matter) whose filename is identical to the name of your training dataset. E.g. 'C:/PigDLC/pig20190227.avi'. This dataset name (pig20190227) will stay consistent throughout the iterative retraining of the two networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set working directory paths for cam1 and cam2, if you haven't yet\n",
    "\n",
    "path_config_file_cam1 = 'C:/Users/jdlc7/PigDLC_cam1/PigFeeding-JD-2019-02-27/config.yaml'\n",
    "path_config_file_cam2 = 'C:/Users/jdlc7/PigDLC_cam2/PigFeeding-JD-2019-02-27/config.yaml'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Uoz9mdPoEIy"
   },
   "source": [
    "## Convert XMALab 2D points to DLC format\n",
    "\n",
    "Now we generate a training dataset from the 2D points file/s exported from XMALab and frames from the videos. The function xma2dlc will populate each projects labeled-data folder with the extracted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c9DjG55FoEI7",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "experimenter = 'JD'\n",
    "data_path = 'C:/Users/jdlc7/Pig20190227/DLC' # where are the trial folders (with 2D points/trial images)\n",
    "dataset_name = 'pig20190227' # IMPORTANT, omit the _cam1/_cam2\n",
    "nframes = 400 # how many frames do you want the training dataset to comprise?\n",
    "\n",
    "xrommtools.xma2dlc(path_config_file_cam1,path_config_file_cam2,data_path,dataset_name,experimenter,nframes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xNi9s1dboEJN"
   },
   "source": [
    "## Create a training dataset\n",
    "\n",
    "This function generates the training data information for network training based on the pandas dataframes that hold label information. The user can set the fraction of the training set size (from all labeled image in the hd5 file) in the config.yaml file. While creating the dataset, the user can create multiple shuffles if they want to benchmark the performance (typically, 1 is what you will set, so you pass nothing!). \n",
    "\n",
    "After running this script the training dataset is created and saved in the project directory under the subdirectory **'training-datasets'**\n",
    "\n",
    "This function also creates new subdirectories under **dlc-models** and appends the project config.yaml file with the correct path to the training and testing pose configuration file. These files hold the parameters for training the network. Such an example file is provided with the toolbox and named as **pose_cfg.yaml**. For most all use cases we have seen, the defaults are perfectly fine.\n",
    "\n",
    "Now it is the time to start training the network!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eMeUwgxPoEJP",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file_cam1)\n",
    "deeplabcut.create_training_dataset(path_config_file_cam2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c4FczXGDoEJU"
   },
   "source": [
    "## Start training:\n",
    "\n",
    "This function trains the network for a specific shuffle of the training dataset. This will take a long time. You can stop training manually by hitting stop. It will look like an error has occured...it has not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_pOvDq_2oEJW"
   },
   "outputs": [],
   "source": [
    "deeplabcut.train_network(path_config_file_cam1,maxiters = 500000)\n",
    "\n",
    "tf.reset_network()\n",
    "\n",
    "deeplabcut.train_network(path_config_file_cam2,maxiters = 500000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZygsb2DoEJc"
   },
   "source": [
    "## Start evaluating\n",
    "This funtion evaluates a trained model for a specific shuffle/shuffles at a particular state or all the states on the data set (images)\n",
    "and stores the results as .csv file in a subdirectory under **evaluation-results**. The values here can give you an indication of performance/generalizability, but are less informative than reprojection error and other XMALab metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nv4zlbrnoEJg"
   },
   "outputs": [],
   "source": [
    "deeplabcut.evaluate_network(path_config_file_cam1, plotting=True)\n",
    "deeplabcut.evaluate_network(path_config_file_cam2, plotting=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OVFLSKKfoEJk"
   },
   "source": [
    "## Analyzing videos\n",
    "This function uses the existing DLC function analyze_videos to predict points for new trials and convert the output to XMALab format. The results are stored in hd5 file and CSV file in each trial's specific iteration subfolder.\n",
    "\n",
    "The base function analyze_videos has many possible arguments. To alter this, you will need to edit the xrommtools script manually. Its default form should be sufficient in most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y_LZiS_0oEJl"
   },
   "outputs": [],
   "source": [
    "new_data_path = '' # where are the trials you wish to analyze? \n",
    "# IMPORTANT: data_path must only contain trial folders. Any other files/folders will cause an error\n",
    "\n",
    "iteration = 0 # what iteration of the network do you want to analyze the videos?\n",
    "\n",
    "xrommtools.analyze_xromm_videos(path_config_file_cam1,path_config_file_cam2,new_data_path,iteration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QCHj7qyboEJ6"
   },
   "source": [
    "## Create a new iteration of training dataset [optional step]\n",
    "Following the correction of frames in XMALab and the re-exporting of 2D points, you can augment the training dataset and retrain the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ytQoxIldoEJ7"
   },
   "outputs": [],
   "source": [
    "frames = 'C:/Users/jdlc7/PigDLC/frameindex.csv' # column 1 should be trialnames, and columns 2+ should be frame numbers\n",
    "\n",
    "# data_path = where are trial folders with new videos to analyze?\n",
    "\n",
    "xrommtools.add_frames(path_config_file_cam1, path_config_file_cam2, data_path, iteration, frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT!!!: Before creating new training dataset, update the iteration value in the two configuration files (i.e. 0 --> 1).\n",
    "\n",
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pCrUvQIvoEKD"
   },
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. \n",
    "\n",
    "THIS HAS MANY FUN OPTIONS! \n",
    "\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6aDF7Q7KoEKE"
   },
   "outputs": [],
   "source": [
    "deeplabcut.create_labeled_video(path_config_file,videofile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8GTiuJESoEKH"
   },
   "source": [
    "## Plot the trajectories of the analyzed videos\n",
    "This function plots the trajectories of all the body parts across the entire video. Each body part is identified by a unique color."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gX21zZbXoEKJ"
   },
   "outputs": [],
   "source": [
    "%matplotlib notebook #for making interactive plots.\n",
    "deeplabcut.plot_trajectories(path_config_file,videofile_path)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Demo-yourowndata.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [conda env:dlc-windowsCPU] *",
   "language": "python",
   "name": "conda-env-dlc-windowsCPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
